{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f9adb1",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f04c5",
   "metadata": {},
   "source": [
    "### A confusion matrix is a table used to evaluate the performance of a classification model by comparing actual values with predicted values. It shows the counts of True Positives, True Negatives, False Positives, and False Negatives, helping to compute metrics like accuracy, precision, recall, and F1-score and understand where the model makes errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce493450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9694deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Answers\n",
    "y_true = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
    "# Model Predictions\n",
    "y_pred = [1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f96ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fe0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
